{
  "version": 3,
  "file": "",
  "sourceRoot": "",
  "sources": [
    "../src/import-export-mixin.coffee"
  ],
  "names": [],
  "mappings": "AAEA;EAAA;AAAA,MAAA,GAAA,EAAA,CAAA,EAAA,EAAA,EAAA,IAAA,EAAA,KAAA,EAAA,KAAA,EAAA,IAAA,EAAA,IAAA,EAAA,IAAA,EAAA,MAAA,EAAA,GAAA,EAAA,IAAA,EAAA,IAAA,EAAA,OAAA;;;EAGA,GAAA,GAA4B,OAAA,CAAQ,KAAR;;EAC5B,GAAA,GAA4B,GAAG,CAAC;;EAChC,KAAA,GAA4B;;EAC5B,KAAA,GAA4B,GAAG,CAAC,UAAJ,CAAe,OAAf,EAA4B,KAA5B;;EAC5B,IAAA,GAA4B,GAAG,CAAC,UAAJ,CAAe,MAAf,EAA4B,KAA5B;;EAC5B,IAAA,GAA4B,GAAG,CAAC,UAAJ,CAAe,MAAf,EAA4B,KAA5B;;EAC5B,IAAA,GAA4B,GAAG,CAAC,UAAJ,CAAe,MAAf,EAA4B,KAA5B;;EAC5B,IAAA,GAA4B,GAAG,CAAC,UAAJ,CAAe,MAAf,EAA4B,KAA5B;;EAC5B,OAAA,GAA4B,GAAG,CAAC,UAAJ,CAAe,SAAf,EAA4B,KAA5B;;EAC5B,IAAA,GAA4B,GAAG,CAAC,IAAI,CAAC,IAAT,CAAc,GAAd,EAZ5B;;;EAcA,IAAA,GAA4B,OAAA,CAAQ,MAAR;;EAC5B,EAAA,GAA4B,OAAA,CAAQ,IAAR;;EAC5B,CAAA,GAA4B,OAAA,CAAQ,UAAR;;EAC5B,CAAA,CAAE,MAAF,CAAA,GAA4B,OAAA,CAAQ,UAAR,CAA5B,EAjBA;;;EAoBA,IAAC,CAAA,mBAAD,GAAuB,CAAE,QAAQ,MAAV,CAAA,GAAA;WAAsB,MAAA,QAAc,MAAd,CAAA;;MAG3C,MAAQ,CAAE,GAAF,CAAA;QACN,GAAA,GAAc,CAAE,GAAA,IAAC,CAAA,KAAK,CAAC,QAAQ,CAAC,cAAlB,EAAqC,GAAA,GAArC;;UACd,GAAG,CAAC,SAAU,IAAC,CAAA,iBAAD,CAAmB,GAAG,CAAC,IAAvB;;QACd,IAAC,CAAA,KAAK,CAAC,QAAQ,CAAC,cAAhB,CAA+B,GAA/B;AACA,gBAAO,GAAG,CAAC,MAAX;AAAA,eACO,IADP;YACmB,IAAC,CAAA,UAAD,CAAa,GAAb;AAAZ;AADP,eAEO,KAFP;YAEmB,IAAC,CAAA,WAAD,CAAa,GAAb;AAAZ;AAFP,eAGO,KAHP;YAGmB,IAAC,CAAA,WAAD,CAAa,GAAb;AAAZ;AAHP;YAKI,MAAM,IAAI,CAAC,CAAC,kBAAN,CAAyB,WAAzB,EAAsC,MAAtC;AALV;AAMA,eAAO;MAVD,CADV;;;;;MAiBE,oBAAsB,CAAE,IAAF,CAAA;AAAW,YAAA;QAAC,IAAG,CAAE,CAAA,GAAI,IAAI,CAAC,OAAL,CAAa,IAAb,CAAN,CAAA,KAA6B,EAAhC;iBAAwC,KAAxC;SAAA,MAAA;iBAAkD,CAAC,UAAnD;;MAAZ;;MACtB,iBAAsB,CAAE,IAAF,CAAA;AAAW,YAAA;sFAA4C;MAAvD,CAlBxB;;;MAsBE,UAAY,CAAE,GAAF,CAAA;AACd,YAAA;QAAI,UAAA,GAAa,IAAC,CAAA,qBAAD,CAAA;QACb,IAAC,CAAA,OAAD,CAAS;UAAE,MAAA,EAAQ,UAAV;UAAsB,IAAA,EAAM,GAAG,CAAC;QAAhC,CAAT,EADJ;;QAGI,IAAC,CAAA,OAAD,CAAS;UAAE,MAAA,EAAQ,GAAG,CAAC,MAAd;UAAsB,IAAA,EAAM;QAA5B,CAAT,EAHJ;;QAKI,IAAC,CAAA,WAAD,CAAa;UAAE,WAAA,EAAa,UAAf;UAA2B,SAAA,EAAW,GAAG,CAAC;QAA1C,CAAb;QACA,IAAC,CAAA,OAAD,CAAS;UAAE,MAAA,EAAQ;QAAV,CAAT;AACA,eAAO;MARG,CAtBd;;;MAiCE,WAAa,CAAE,GAAF,CAAA;QACX,MAAM,IAAI,CAAC,CAAC,kBAAN,CAAyB,WAAzB,EAAsC,KAAtC;MADK,CAjCf;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;MAuFE,WAAa,CAAE,GAAF,CAAA,EAAA;;;;;;;;AACf,YAAA,MAAA,EAAA,UAAA,EAAA,MAAA,EAAA,OAAA,EAAA,OAAA,EAAA,KAAA,EAAA,MAAA,EAAA,IAAA,EAAA,GAAA,EAAA,KAAA,EAAA,IAAA,EAAA,SAAA,EAAA,MAAA,EAAA,UAAA,EAAA,UAAA,EAAA,IAAA,EAAA,KAAA,EAAA;QAOI,KAAA,GAAc,OAAA,CAAQ,oBAAR;QACd,GAAA,GAAc,CACZ,GAAA,IAAC,CAAA,KAAK,CAAC,QAAQ,CAAC,cADJ,EAEZ,GAAA,IAAC,CAAA,KAAK,CAAC,QAAQ,CAAC,kBAFJ,EAGZ,GAAA,GAHY;QAId,IAAC,CAAA,KAAK,CAAC,QAAQ,CAAC,kBAAhB,CAAmC,GAAnC;QACA,CAAA,CAAE,IAAF,EACE,MADF,EAEE,SAFF,EAGE,OAHF,EAIE,UAJF,EAKE,UALF,EAME,MANF,EAOE,KAPF,CAAA,GAOc,GAPd;QAQA,OAAA,GAAc,CAAE,GAAA,IAAC,CAAA,KAAK,CAAC,QAAQ,CAAC,wBAAlB,EAA+C,GAAA,MAA/C,EAA0D,OAA1D;QACd,IAAC,CAAA,KAAK,CAAC,QAAQ,CAAC,wBAAhB,CAAyC,OAAzC;QACA,SAAA,GAAc,IAAI,CAAE,OAAA,CAAQ,aAAR,CAAF,CAAJ,CAA8B,IAA9B;QACd,IAAA,GAAc,MAAM,CAAC,GAAP,CAAW,MAAX;QACd,GAAA,GAAc;QACd,MAAA,GAAc;QACd,UAAA,GAAc;QACd,IAAC,CAAA,OAAD,CAAS;UAAE,MAAF;UAAU,GAAA,EAAK;QAAf,CAAT;QACA,MAAA,GAAc,KA7BlB;;QA+BI,KAAA,GAAQ,CAAA,CAAA,GAAA;AACZ,cAAA,MAAA,EAAA,CAAA,EAAA,CAAA,EAAA,GAAA,EAAA,IAAA,EAAA,IAAA,EAAA,KAAA,EAAA,GAAA,EAAA,OAAA,EAAA,IAAA,EAAA,MAAA,EAAA,MAAA,EAAA;UAAM,MAAc,gBAAA,IAAY,MAAM,CAAC,MAAP,GAAgB,EAA1C;AAAA,mBAAA;;UACA,KAAA,GAAU;UACV,MAAA,GAAU,KAAK,CAAC,IAAN,CAAW,IAAX;UACV,MAAA,GAAU;UACV,IAAA,GAAU,KAAA,CAAM,MAAN,EAAc,OAAd,EAJhB;;;;;;;;;;YAaM,SAAU,IAAC,CAAA,iBAAD,CAAmB,CAAE,MAAF,EAAU,KAAV,EAAiB,OAAjB,CAAnB;WAbhB;;UAeM,KAAA,0DAAA;;YACE,IAAO,iBAAP;cACE,MAAM,CAAC,GAAP;;AAAa;gBAAA,KAAA,2CAAA;;+BAAA,GAAG,CAAE,MAAF;gBAAH,CAAA;;kBAAb;AACA,uBAFF;;YAGA,IAAA,GAAY,KAAK,CAAE,OAAF,CAAW,CAAC,QAAjB,CAA0B,OAA1B;YACZ,GAAA;YACA,IAAY,UAAA,IAAe,IAAA,KAAQ,EAAnC;AAAA,uBAAA;;YACA,IAAY,UAAA,IAAe,OAAO,CAAC,IAAR,CAAa,IAAb,CAA3B;AAAA,uBAAA;;YACA,OAAA,GAAY,SAAA,CAAU,CAAE,GAAF,EAAO,GAAP,EAAY,IAAZ,EAAkB,IAAlB,CAAV;YACZ,IAAS,OAAA,KAAW,IAApB;AAAA,oBAAA;;YACA,IAAgB,eAAhB;AAAA,uBAAA;;YACA,IAAG,IAAC,CAAA,KAAK,CAAC,GAAG,CAAC,IAAX,CAAgB,OAAhB,CAAH;cACE,KAAA,2CAAA;;gBACE,MAAM,CAAC,GAAP;;AAAa;kBAAA,KAAA,2CAAA;;iCAAA,MAAM,CAAE,MAAF;kBAAN,CAAA;;oBAAb;cADF;AAEA,uBAHF;;YAIA,MAAM,CAAC,GAAP;;AAAa;cAAA,KAAA,2CAAA;;6BAAA,OAAO,CAAE,MAAF;cAAP,CAAA;;gBAAb;UAfF;AAgBA,iBAAO;QAhCD,EA/BZ;;;;;AAoEI,eAAM,CAAE,IAAA,GAAO,SAAS,CAAC,IAAV,CAAA,CAAT,CAAA,KAAiC,KAAvC;UACE,kBAAE,SAAA,SAAU,EAAZ,CAAgB,CAAC,IAAjB,CAAsB,IAAtB;UACA,IAAW,MAAM,CAAC,MAAP,IAAiB,UAA5B;YAAA,KAAA,CAAA,EAAA;;QAFF;QAGA,KAAA,CAAA;AACA,eAAO;MAzEI,CAvFf;;;MAmKE,iBAAmB,CAAE,GAAF,CAAA;AACrB,YAAA,EAAA,EAAA,OAAA,EAAA,SAAA,EAAA,WAAA,EAAA,UAAA,EAAA,CAAA,EAAA,eAAA,EAAA,MAAA,EAAA,QAAA,EAAA,KAAA,EAAA;QAAI,CAAA,CAAE,MAAF,EACE,KADF,EAEE,OAFF,CAAA,GAEkB,GAFlB;QAGA,QAAA,GAAkB,IAAC,CAAA,aAAD,CAAe,MAAf;QAClB,OAAA,GAAkB,IAAC,CAAA,aAAD,CAAe,KAAf;QAClB,SAAA;;AAAoB;UAAA,KAAA,yCAAA;;yBAAA,IAAC,CAAA,aAAD,CAAe,CAAf;UAAA,CAAA;;;QACpB,WAAA,GAAkB;;AAAE;UAAA,KAAA,2CAAA;;yBAAA,CAAA,CAAA,CAAG,EAAH,CAAA,KAAA;UAAA,CAAA;;YAAF,CAAqC,CAAC,IAAtC,CAA2C,IAA3C;QAClB,eAAA,GAAkB;;AAAE;UAAA,KAAA,2CAAA;;yBAAA;UAAA,CAAA;;YAAF,CAAqC,CAAC,IAAtC,CAA2C,IAA3C;QAClB,UAAA,GAAkB,CAAA,aAAA,CAAA,CAAgB,QAAhB,CAAA,CAAA,CAAA,CAA4B,OAA5B,CAAA,GAAA,CAAA,CAAyC,WAAzC,CAAA,GAAA;QAClB,IAAC,CAAA,OAAD,CAAS,UAAT,EATJ;;AAWI,eAAO,IAAC,CAAA,OAAD,CAAS,CAAA,YAAA,CAAA,CAAe,QAAf,CAAA,CAAA,CAAA,CAA2B,OAA3B,CAAA,UAAA,CAAA,CAA+C,eAA/C,CAAA,GAAA,CAAT;MAZU,CAnKrB;;;MAkLE,kBAAoB,CAAE,GAAF,CAAA;QAClB,IAAC,CAAA,OAAD,CAAS,EAAE,CAAC,YAAH,CAAgB,GAAG,CAAC,IAApB,EAA0B;UAAE,QAAA,EAAU;QAAZ,CAA1B,CAAT;AACA,eAAO;MAFW,CAlLtB;;;MAuLE,iBAAmB,CAAE,GAAF,CAAA;AACrB,YAAA,kBAAA,EAAA,GAAA,EAAA;AAAI;QAAA,KAAA,iBAAA;UACE,kBAAA,GAAsB,UAAU,CAAC,IAAX,CAAgB,EAAhB;UACtB,KAAA,IAAsB,kBAAkB,CAAC;UACzC,IAAC,CAAA,OAAD,CAAS,kBAAT;QAHF;AAIA,eAAO;MALU,CAvLrB;;;MA+L8B,EAA5B,0BAA4B,CAAE,QAAF,CAAA,EAAA;;;;;AAC9B,YAAA,GAAA,EAAA,SAAA,EAAA,OAAA,EAAA,KAAA,EAAA,CAAA,EAAA,GAAA,EAAA,IAAA,EAAA,SAAA,EAAA,GAAA,EAAA,KAAA,EAAA;QAII,SAAA,GAAkB,IAAI,CAAE,OAAA,CAAQ,aAAR,CAAF,CAAJ,CAA8B,QAA9B,EAJtB;;QAMI,GAAA,GACE;UAAA,MAAA,EAAU,OAAA,CAAQ,kCAAR;QAAV;QACF,QAAA,GAAgB,CAAE,OAAA,CAAQ,iBAAR,CAAF,CAAA,CAA8B,GAA9B;QAChB,SAAA,GAAgB,KATpB;;;QAYI,KAAA,GAAQ,QAAA,CAAA,CAAA;AACZ,cAAA;UAAM,CAAA,GAAY,SAAS,CAAC,IAAV,CAAe,EAAf;UACZ,SAAA,GAAY;AACZ,iBAAO;QAHD,EAZZ;;AAiBI,eAAM,CAAE,IAAA,GAAO,SAAS,CAAC,IAAV,CAAA,CAAT,CAAA,KAAiC,KAAvC;AACE;UAAA,KAAA,yDAAA;;YACE,IAAG,KAAA,KAAS,GAAZ;cACE,qBAAE,YAAA,YAAa,EAAf,CAAmB,CAAC,IAApB,CAAyB,KAAzB;cACA,MAAM,KAAA,CAAA;AACN,uBAHF;aAAR;;;YAMQ,qBAAE,YAAA,YAAa,EAAf,CAAmB,CAAC,IAApB,CAAyB,KAAzB;UAPF;QADF;QAUA,IAAiB,iBAAjB;;UAAA,MAAM,KAAA,CAAA,EAAN;;AACA,eAAO;MA7BmB,CA/L9B;;;MA+NiB,EAAf,aAAe,CAAE,QAAF,EAAY,aAAa,CAAzB,CAAA,EAAA;;AACjB,YAAA,KAAA,EAAA;QACI,KAAA,GAAQ;QACR,KAAA,aAAA;UACE,iBAAE,QAAA,QAAS,EAAX,CAAe,CAAC,IAAhB,CAAqB,CAArB;UACA,IAAG,KAAK,CAAC,MAAN,IAAgB,UAAnB;YACE,MAAM;YACN,KAAA,GAAQ,KAFV;;QAFF;QAKA,IAAe,aAAf;UAAA,MAAM,MAAN;;AACA,eAAO;MATM;;IAjO4B;EAAtB;AApBvB",
  "sourcesContent": [
    "\n\n'use strict'\n\n############################################################################################################\nCND                       = require 'cnd'\nrpr                       = CND.rpr\nbadge                     = 'ICQL-DBA/IMPORT-EXPORT-MIXIN'\ndebug                     = CND.get_logger 'debug',     badge\nwarn                      = CND.get_logger 'warn',      badge\ninfo                      = CND.get_logger 'info',      badge\nurge                      = CND.get_logger 'urge',      badge\nhelp                      = CND.get_logger 'help',      badge\nwhisper                   = CND.get_logger 'whisper',   badge\necho                      = CND.echo.bind CND\n#...........................................................................................................\nPATH                      = require 'path'\nFS                        = require 'fs'\nE                         = require './errors'\n{ misfit }                = require './common'\n\n#-----------------------------------------------------------------------------------------------------------\n@Import_export_mixin = ( clasz = Object ) => class extends clasz\n\n  #---------------------------------------------------------------------------------------------------------\n  import: ( cfg ) ->\n    cfg         = { @types.defaults.dba_import_cfg..., cfg..., }\n    cfg.format ?= @_format_from_path cfg.path\n    @types.validate.dba_import_cfg cfg\n    switch cfg.format\n      when 'db'   then @_import_db  cfg\n      when 'sql'  then @_import_sql cfg\n      when 'csv'  then @_import_csv cfg\n      else\n        throw new E.Dba_format_unknown '^dba@309^', format\n    return null\n\n\n  #=========================================================================================================\n  # FORMAT GUESSING\n  #---------------------------------------------------------------------------------------------------------\n  _extension_from_path: ( path ) -> if ( R = PATH.extname path ) is '' then null else R[ 1 .. ]\n  _format_from_path:    ( path ) -> @_formats[ @._extension_from_path path ] ? null\n\n\n  #---------------------------------------------------------------------------------------------------------\n  _import_db: ( cfg ) ->\n    tmp_schema = @_get_free_temp_schema()\n    @_attach { schema: tmp_schema, path: cfg.path, }\n    # debug '^469465^', @list_schemas()\n    @_attach { schema: cfg.schema, path: '', }\n    # debug '^469465^', @list_schemas()\n    @copy_schema { from_schema: tmp_schema, to_schema: cfg.schema, }\n    @_detach { schema: tmp_schema, }\n    return null\n\n  #---------------------------------------------------------------------------------------------------------\n  _import_sql: ( cfg ) ->\n    throw new E.Dba_format_unknown '^dba@310^', 'sql'\n    # switch cfg.method\n    #   when 'single' then return @_import_sql_single cfg\n    #   when 'batch'  then return @_import_sql_batch  cfg\n    # return null\n\n  # #---------------------------------------------------------------------------------------------------------\n  # _import_csv1: ( cfg ) ->\n  #   ### TAINT always requires `ram: true` ###\n  #   ### TAINT no streaming, no batching ###\n  #   ### TAINT no configurable CSV parsing ###\n  #   parse       = require 'csv-parse/lib/sync'\n  #   cfg         = {\n  #     @types.defaults.dba_import_cfg...,\n  #     @types.defaults.dba_import_cfg_csv...,\n  #     cfg..., }\n  #   @types.validate.dba_import_cfg_csv cfg\n  #   { path\n  #     schema\n  #     transform\n  #     _extra\n  #     table }   = cfg\n  #   csv_cfg     = { @types.defaults.dba_import_cfg_csv_extra..., _extra..., }\n  #   @types.validate.dba_import_cfg_csv_extra csv_cfg\n  #   source      = FS.readFileSync path, { encoding: 'utf-8', }\n  #   rows        = parse source, csv_cfg\n  #   stop        = Symbol.for 'stop'\n  #   lnr         = 0\n  #   line        = null\n  #   #.......................................................................................................\n  #   unless rows.length > 0\n  #     throw new E.Dba_empty_csv '^dba@333^', path\n  #   #.......................................................................................................\n  #   columns = ( k for k of rows[ 0 ] )\n  #   columns = transform { columns, } if transform?\n  #   @_attach { schema, ram: true, }\n  #   insert  = @_create_csv_table { schema, table, columns, }\n  #   #.......................................................................................................\n  #   for row in rows\n  #     unless transform?\n  #       insert.run ( row[ column ] for column in columns )\n  #       continue\n  #     subrows   = transform { row, lnr, line, stop, }\n  #     break if subrows is stop\n  #     continue unless subrows?\n  #     if @types.isa.list subrows\n  #       for subrow in subrows\n  #         insert.run ( subrow[ column ] for column in columns )\n  #       continue\n  #     insert.run ( subrows[ column ] for column in columns )\n  #   return null\n\n  #---------------------------------------------------------------------------------------------------------\n  _import_csv: ( cfg ) ->\n    ### TAINT always requires `ram: true` ###\n    ### TAINT no streaming, no batching ###\n    ### TAINT no configurable CSV parsing ###\n    ### NOTE optimisation: instead of n-readlines, use (unpublished) `chunkreader` that reads n bytes,\n      only looks for last newline, then parses chunk ###\n    ### NOTE optimisation: do not call `insert` for each line, but assemble big `insert .. values (...)`\n      statement (as done before, should be fastest) ###\n    parse       = require 'csv-parse/lib/sync'\n    cfg         = {\n      @types.defaults.dba_import_cfg...,\n      @types.defaults.dba_import_cfg_csv...,\n      cfg..., }\n    @types.validate.dba_import_cfg_csv cfg\n    { path\n      schema\n      transform\n      columns\n      skip_empty\n      skip_blank\n      _extra\n      table }   = cfg\n    csv_cfg     = { @types.defaults.dba_import_cfg_csv_extra..., _extra..., columns, }\n    @types.validate.dba_import_cfg_csv_extra csv_cfg\n    readlines   = new ( require 'n-readlines' ) path\n    stop        = Symbol.for 'stop'\n    lnr         = 0\n    buffer      = null\n    batch_size  = 10000\n    @_attach { schema, ram: true, }\n    insert      = null\n    #.......................................................................................................\n    flush = =>\n      return unless buffer? and buffer.length > 0\n      lines   = buffer\n      source  = lines.join '\\n'\n      buffer  = null\n      rows    = parse source, csv_cfg\n      # #.......................................................................................................\n      # unless rows.length > 0\n      #   throw new E.Dba_empty_csv '^dba@333^', path\n      #.......................................................................................................\n      # columns = ( k for k of rows[ 0 ] )\n      # debug '^443^', { columns, }\n      # columns = transform { columns, } if transform?\n      ### NOTE keeping this here so we can potentially obtain columns from source ###\n      insert ?= @_create_csv_table { schema, table, columns, }\n      #.......................................................................................................\n      for row, row_idx in rows\n        unless transform?\n          insert.run ( row[ column ] for column in columns )\n          continue\n        line      = lines[ row_idx ].toString 'utf-8'\n        lnr++\n        continue if skip_empty and line is ''\n        continue if skip_blank and /^\\s*$/.test line\n        subrows   = transform { row, lnr, line, stop, }\n        break if subrows is stop\n        continue unless subrows?\n        if @types.isa.list subrows\n          for subrow in subrows\n            insert.run ( subrow[ column ] for column in columns )\n          continue\n        insert.run ( subrows[ column ] for column in columns )\n      return null\n    #.......................................................................................................\n    ### TAINT this use of n-readlines is inefficient as it splits the bytes into line-sized chunks which we\n    then re-assembly into strings with lines. However, it only takes up a small part of the overall time\n    it takes to parse and insert records. ###\n    while ( line = readlines.next() ) isnt false\n      ( buffer ?= [] ).push line\n      flush() if buffer.length >= batch_size\n    flush()\n    return null\n\n  #---------------------------------------------------------------------------------------------------------\n  _create_csv_table: ( cfg ) ->\n    { schema\n      table\n      columns }     = cfg\n    schema_i        = @as_identifier schema\n    table_i         = @as_identifier table\n    columns_i       = ( @as_identifier d for d in columns )\n    columns_sql     = ( \"#{ci} text\"  for ci in columns_i ).join ', '\n    placeholder_sql = ( \"?\"           for ci in columns_i ).join ', '\n    create_sql      = \"create table #{schema_i}.#{table_i} ( #{columns_sql} );\"\n    @execute create_sql\n    #.......................................................................................................\n    return @prepare \"insert into #{schema_i}.#{table_i} values ( #{placeholder_sql} );\"\n\n  #---------------------------------------------------------------------------------------------------------\n  _import_sql_single: ( cfg ) ->\n    @execute FS.readFileSync cfg.path, { encoding: 'utf-8', }\n    return null\n\n  #---------------------------------------------------------------------------------------------------------\n  _import_sql_batch: ( cfg ) ->\n    for statements from @_walk_batches ( @_walk_statements_from_path cfg.path ), cfg.batch_size\n      compound_statement  = statements.join ''\n      count              += compound_statement.length\n      @execute compound_statement\n    return null\n\n  #---------------------------------------------------------------------------------------------------------\n  _walk_statements_from_path: ( sql_path ) ->\n    ### Given a path, iterate over SQL statements which are signalled by semicolons (`;`) that appear outside\n    of literals and comments (and the end of input). ###\n    ### thx to https://stackabuse.com/reading-a-file-line-by-line-in-node-js/ ###\n    ### thx to https://github.com/nacholibre/node-readlines ###\n    readlines       = new ( require 'n-readlines' ) sql_path\n    #.......................................................................................................\n    cfg           =\n      regExp: ( require 'mysql-tokenizer/lib/regexp-sql92' )\n    tokenize      = ( require 'mysql-tokenizer' ) cfg\n    collector     = null\n    # stream        = FS.createReadStream sql_path\n    #.......................................................................................................\n    flush = ->\n      R         = collector.join ''\n      collector = null\n      return R\n    #.......................................................................................................\n    while ( line = readlines.next() ) isnt false\n      for token, cur_idx in tokenize line + '\\n'\n        if token is ';'\n          ( collector ?= [] ).push token\n          yield flush()\n          continue\n        # if token.startsWith '--'\n        #   continue\n        ( collector ?= [] ).push token\n    #.......................................................................................................\n    yield flush() if collector?\n    return null\n\n  #---------------------------------------------------------------------------------------------------------\n  _walk_batches: ( iterator, batch_size = 1 ) ->\n    ### Given an iterator and a batch size, iterate over lists of values yielded by the iterator. ###\n    batch = null\n    for d from iterator\n      ( batch ?= [] ).push d\n      if batch.length >= batch_size\n        yield batch\n        batch = null\n    yield batch if batch?\n    return null\n"
  ]
}